[file_path]
; prefix of saving dir
prefix = .
; base dir, in which the dataset is saved
dataset_base_dir = generated_datasets
result_saving_base_dir = NIPS_results2

; Below items are for testing
; dir to save models
model_saving_dir = ${prefix}/${result_saving_base_dir}/${model:model_name}/models
; dir to save graphs, which will be plotted in model testing
test_results_saving_base_dir = ${prefix}/NIPS_results

[dataset]
; dir name of your dataset, dataset_base_dir/dataset_name should be the absolute path of dataset
dataset_name = data-no-mask-cloud
; sequence length, namely the num of past days
seq_len = 75
; num of input features
feature_num = 10
; batch size
batch_size = 256
; num of workers in dataloader
num_workers = 8
; evaluate every n steps
eval_every_n_steps = 1500

[model]
; name of your model, will be the name of dir to save your models and logs
model_name = PhysioNet2012_SAITS_best
; whether concat input with missing mask
input_with_mask = False
; model type, Transformer/SAITS
model_type = SAITS_for_CACM
; num of layer groups
; n_groups = 5
n_groups = 6
; num of group-inner layers
n_group_inner_layers = 1
; how to share parameters, inner_group/between_group
param_sharing_strategy = inner_group
; model hidden dim
d_model = 256
; hidden size of feed forward layer
d_inner = 512
; head num of self-attention
n_head = 8
; key dim
d_k = 32
; value dim
d_v = 32
; drop out rate
dropout = 0
; whether to apply diagonal attention mask
diagonal_attention_mask = True

[training]
; whether to have Masked Imputation Task (MIT) in training
MIT = True
; whether to have Observed Reconstruction Task (ORT) in training
ORT = True
;calculate total_variation_loss for smooth time-series
TV = True
; max num of training epochs
epochs = 10000
; which device for training, cpu/cuda
device = cuda
; learning rate
lr = 0.00068277455043675505
; weight for reconstruction loss
reconstruction_loss_weight = 5
; weight for imputation loss
imputation_loss_weight = 1
; weiht for variation_loss_weight
total_variation_loss_weight = 0.5
; patience of early stopping, -1 means not applied (current early stopping is based on total loss)
early_stop_patience = 30
; what type of optimizer to use, adam/adamw
optimizer_type = adam
; weight decay used in optimizer
weight_decay = 0
; max_norm for gradient clipping, set 0 to disable
max_norm = 0
; strategy on model saving, all/best/none. If set as none, then do not save models (mode for hyper-parameter searching)
model_saving_strategy = best

[test]
; whether to save imputed data
save_imputations = True
; name of model your select for testing
; step_313 = model_trainStep_18780_valStep_313_imputationMAE_0.1904
step_313 = model_train_val_test_trainStep_1132000_valStep_566_imputationMAE_0.1810
; absolute path to locate model you select
model_path = ${file_path:model_saving_dir}/${step_313}
; path of dir to save generated figs (PR-curve etc.)
result_saving_path = ${file_path:test_results_saving_base_dir}/${model:model_name}/step_313
